{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6462427d-f93a-46a3-aef1-f16e7a7f7bbd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Questions on Combining Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a0c2c3-3e22-4597-af3a-71beca5eede0",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ee0b18-14aa-477b-bbf2-fb5c03b7abec",
   "metadata": {},
   "source": [
    "Can the generation of a random forest with 100 trees be at least as fast as the generation of a single decision tree (using the standard divide-and-conquer algorithm)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e3f7d0-cae5-4ec6-8f3f-487203568c54",
   "metadata": {},
   "source": [
    "A: Yes, but only if the trees in the forest are generated in parallel\n",
    "\n",
    "B: Yes, if the number of training instances is large enough\n",
    "\n",
    "C: Yes, if the number of features is large enough"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584e7087-3555-4536-b621-0515ed07b2cb",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cd8e3c-8e2f-465d-b1f3-6d6bd466def0",
   "metadata": {},
   "source": [
    "Assume that we want to apply both random forests (RF) and the gradient boosting\n",
    "machine (GBM) to a regression task, where all regression values in the training set fall\n",
    "into the range $[0,1]$. Which of the following are correct?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f08207-06e2-4dbf-aa35-3845df086260",
   "metadata": {},
   "source": [
    "A: RF may produce predictions outside the range $[0,1]$\n",
    "\n",
    "B: GBM may produce predictions outside the range $[0,1]$\n",
    "\n",
    "C: Whether RF may produce predictions outside the range depends on the number of trees\n",
    "\n",
    "D: Whether GBM may produce predictions outside the range depends on the number of base models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9623cc6c-e3ed-432b-b6a8-43ece77d34c9",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9730b20b-5366-4ba5-a5f4-82e6171522f0",
   "metadata": {},
   "source": [
    "Assume that we would like to generate an ensemble of Naive Bayes classifiers in a similar way to how random forests are trained.\n",
    "\n",
    "Which of the following statements are correct?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ab7f50-f79d-43aa-9906-960c4dbda555",
   "metadata": {},
   "source": [
    "A Bagging can be employed\n",
    "\n",
    "B Random feature selection can be employed\n",
    "\n",
    "C The class priors may differ between the base models\n",
    "\n",
    "D Numerical features have to be discretized in the same way across the base models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee2962f-dab7-4ccc-a1cd-8d613af132a2",
   "metadata": {},
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d1224e-7e5d-4544-827d-f623354782cb",
   "metadata": {},
   "source": [
    "Assume that we would like to compare AdaBoost using decision stumps and fully grown decision trees as base models, respectively.\n",
    "\n",
    "Which of the following statements are correct?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5522d4-1135-444a-8e9e-25870ad076f9",
   "metadata": {},
   "source": [
    "A: We can expect more base models to be generated when using stumps\n",
    "\n",
    "B: We can expect the accuracy to be higher when using fully grown trees compared to using stumps\n",
    "\n",
    "C: We can expect that using more base models leads to improved predictive performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2adaf2-2a35-4419-8be8-bceda2bfcc5d",
   "metadata": {},
   "source": [
    "## Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662d45b3-a1a1-431f-ae2f-4106f5975147",
   "metadata": {},
   "source": [
    "Assume that we first train base models using a set of algorithms\n",
    "from a given dataset and then generate a stacked model from the output of\n",
    "the base models when given the same dataset as input.\n",
    "\n",
    "Which of the following statements are correct?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e353271-fc0b-4313-a910-ddecbe4d3658",
   "metadata": {},
   "source": [
    "A: We can expect the stacked model to outperform each of the individual models\n",
    "\n",
    "B: If one base model is overfitting the training set, this will be compensated for by having included other base models\n",
    "\n",
    "C: We can expect averaging of the base models to outperform the stacked model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813c5d30-0007-4b65-a251-0f27ae52bcc3",
   "metadata": {},
   "source": [
    "## Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5251e9a6-982e-4e51-a319-5b45b1f03dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "rng = np.random.default_rng()\n",
    "\n",
    "# Now write:\n",
    "# rng.choice([1,2,3],10)\n",
    "# instead of (legacy):\n",
    "# np.random.choice([1,2,3],10)\n",
    "\n",
    "n = 10\n",
    "d = 5\n",
    "X = rng.random((n,d))\n",
    "y = rng.choice([0,1], n)\n",
    "\n",
    "# Which of the following results in a proper \n",
    "# bootstrap replicate of the objects and labels:\n",
    "\n",
    "# A\n",
    "X_bootstrap = X[rng.choice(n,n,replace=False)]\n",
    "y_bootstrap = y[rng.choice(n,n,replace=False)]\n",
    "\n",
    "# B\n",
    "X_bootstrap = X[rng.choice(n,n,replace=True)]\n",
    "y_bootstrap = y[rng.choice(n,n,replace=True)]\n",
    "\n",
    "# C\n",
    "bootstrap = rng.choice(n,n,replace=False)\n",
    "X_bootstrap = X[bootstrap]\n",
    "y_bootstrap = y[bootstrap]\n",
    "\n",
    "# D\n",
    "bootstrap = rng.choice(n,n,replace=True)\n",
    "X_bootstrap = X[bootstrap]\n",
    "y_bootstrap = y[bootstrap]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aefd95f0-730b-43f8-a2ef-e3de97f7f403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One more illustration:\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "rng = np.random.default_rng()\n",
    "\n",
    "rng.integers(0,2,5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
